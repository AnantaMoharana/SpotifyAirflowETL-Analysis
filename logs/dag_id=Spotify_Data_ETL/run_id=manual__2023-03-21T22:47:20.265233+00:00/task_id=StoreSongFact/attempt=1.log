[2023-03-21T22:47:24.480+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Spotify_Data_ETL.StoreSongFact manual__2023-03-21T22:47:20.265233+00:00 [queued]>
[2023-03-21T22:47:24.489+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Spotify_Data_ETL.StoreSongFact manual__2023-03-21T22:47:20.265233+00:00 [queued]>
[2023-03-21T22:47:24.490+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T22:47:24.495+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 3
[2023-03-21T22:47:24.495+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T22:47:24.591+0000] {taskinstance.py:1303} INFO - Executing <Task(S3ToSnowflakeOperator): StoreSongFact> on 2023-03-21 22:47:20.265233+00:00
[2023-03-21T22:47:24.624+0000] {standard_task_runner.py:55} INFO - Started process 21651 to run task
[2023-03-21T22:47:24.710+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Spotify_Data_ETL', 'StoreSongFact', 'manual__2023-03-21T22:47:20.265233+00:00', '--job-id', '2234', '--raw', '--subdir', 'DAGS_FOLDER/spotifydag.py', '--cfg-path', '/tmp/tmpf9o80u_y']
[2023-03-21T22:47:24.725+0000] {standard_task_runner.py:83} INFO - Job 2234: Subtask StoreSongFact
[2023-03-21T22:47:24.966+0000] {task_command.py:388} INFO - Running <TaskInstance: Spotify_Data_ETL.StoreSongFact manual__2023-03-21T22:47:20.265233+00:00 [running]> on host 1fd7b08731f2
[2023-03-21T22:47:25.134+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Ananta Moharana
AIRFLOW_CTX_DAG_ID=Spotify_Data_ETL
AIRFLOW_CTX_TASK_ID=StoreSongFact
AIRFLOW_CTX_EXECUTION_DATE=2023-03-21T22:47:20.265233+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-03-21T22:47:20.265233+00:00
[2023-03-21T22:47:25.141+0000] {s3_to_snowflake.py:146} INFO - Executing COPY command...
[2023-03-21T22:47:25.153+0000] {base.py:73} INFO - Using connection ID 'snowflake_connection' for task execution.
[2023-03-21T22:47:25.157+0000] {connection.py:287} INFO - Snowflake Connector for Python Version: 3.0.1, Python Version: 3.7.16, Platform: Linux-5.15.49-linuxkit-aarch64-with-debian-11.6
[2023-03-21T22:47:25.161+0000] {connection.py:990} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-03-21T22:47:25.161+0000] {connection.py:1007} INFO - Setting use_openssl_only mode to False
[2023-03-21T22:47:25.835+0000] {cursor.py:738} INFO - query: [ALTER SESSION SET autocommit=True]
[2023-03-21T22:47:25.924+0000] {cursor.py:751} INFO - query execution done
[2023-03-21T22:47:25.925+0000] {cursor.py:891} INFO - Number of results in first chunk: 1
[2023-03-21T22:47:25.925+0000] {sql.py:375} INFO - Running statement: COPY INTO SpotifyTop50USA.song_fact
FROM @s3_snowflake_stage/
files=('2023-03-21/song_fact.csv')
file_format=DATA_CSV, parameters: None
[2023-03-21T22:47:25.926+0000] {cursor.py:738} INFO - query: [COPY INTO SpotifyTop50USA.song_fact FROM @s3_snowflake_stage/ files=('2023-03-21...]
[2023-03-21T22:47:26.123+0000] {cursor.py:751} INFO - query execution done
[2023-03-21T22:47:26.128+0000] {connection.py:586} INFO - closed
[2023-03-21T22:47:26.152+0000] {connection.py:589} INFO - No async queries seem to be running, deleting session
[2023-03-21T22:47:26.213+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/snowflake/transfers/s3_to_snowflake.py", line 147, in execute
    snowflake_hook.run(copy_query, self.autocommit)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 379, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/cursor.py", line 839, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/errors.py", line 294, in errorhandler_wrapper
    error_value,
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/errors.py", line 231, in default_errorhandler
    cursor=cursor,
snowflake.connector.errors.ProgrammingError: 091016 (22000): 01ab1a77-0004-6150-0000-00552087e0fd: Remote file 's3://spotify-top-50/2023-03-21/song_fact.csv' was not found. If you are running a copy command, please make sure files are not deleted when they are being loaded or files are not being loaded into two different tables concurrently with auto purge option.
[2023-03-21T22:47:26.233+0000] {taskinstance.py:1326} INFO - Marking task as UP_FOR_RETRY. dag_id=Spotify_Data_ETL, task_id=StoreSongFact, execution_date=20230321T224720, start_date=20230321T224724, end_date=20230321T224726
[2023-03-21T22:47:26.315+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2234 for task StoreSongFact (091016 (22000): 01ab1a77-0004-6150-0000-00552087e0fd: Remote file 's3://spotify-top-50/2023-03-21/song_fact.csv' was not found. If you are running a copy command, please make sure files are not deleted when they are being loaded or files are not being loaded into two different tables concurrently with auto purge option.; 21651)
[2023-03-21T22:47:26.372+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-21T22:47:26.455+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
